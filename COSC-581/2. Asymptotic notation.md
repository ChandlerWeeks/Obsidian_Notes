What to read for next time: 
## Prerequisites for Proofs
Problem with proof by induction
*CONNECT THE BASE TO THE HYPOTHESIS*

**Theorem**: "All horses are the same color"
proof by induction
Basis. True for n=1
Induction Hypothesis: True for arbitrary n.
Induction Step: Must show true for n => true for n +1. 

Consider any collection of n+1 horses.
Place n of them in a corral.
These n are the same color.
Bring in the outside horse and remove an inside horse. 
These n are the same color as well.
Therefore all n+1 horses are the same color. Q.E.D. 

Another problem.
Theorem: All numbers are special.
Proof by contradiction

Not all numbers are special. 
Flaw: The problem is, the first number that is not special, is now special. 
Proofs require mathematical definitions, so words like "special" harm our argument, as they lack a distinct definition. 
Also avoid self-reference. Don't mention the logical statement, such as "this statement is false". 

## Asymptotic notation

f(x) is a function of interest. f(x) is...

- O(g(x)) is a loose upper bound. O(log n) can also be O(N^10) because of constants. This is not how its used in practice. 
- Ω(g(x)) is not quite a lower bound. if there is an epsilon > 0 and infinite set S of natural numbers. Very specific inputs can get lucky, such as an already sorted list, which is why we take out infinite sets. The infinite set is the interesting values, like non-sorted lists for merge sort. 
- Ø(g(x)) is an exact bound by a constant. Most people argue O(n), but theta provides just as much value. 
- o(g(x)) if lim f(x)/g(x) = 0 as n-> infinity. 
- ω(g(x)) if lim f(x)/g(x) = infinity as n-> infinity
- ~(g(x)) if lim f(x)/g(x) = 1 as n-> infinity. Shows the exact behavior of the algorithm, down to the constant of proportionality. 

Our goal is to catch long term behaviors, not spikes at the beginning. That is where "asymptotic" comes from. n_0 is a point where the asymptotic behavior begins.

### Example

Lets compare two functions, n^2 -2 and n^2

- O(g(x)): Because we can multiply n^2 by a c = 2, and make it always greater than n^2 -2 for sufficient n, then we can say n^2 is an upper bound for n^2. Therefore, n^2 - 2 is O(n^2). 
- Ω(g(x)): On the contrary, we can multiply n^2 by a c = 1/2, which will always be lower than n^2 - 2 for a sufficient n. Therefore, n^2 -2 is Ω(n^2). 
	- *Tip: use sufficiently small/large constants, don't just find the smallest one.*
- Ø(g(x)): Because n^2 - 2 is upper bounded and lower bounded by the same function, n^2 - 2 is Ø(n^2). 

Lets write this more mathematically.

f(n) = n^2 - 2
g(n) = n^2
Then f(n) = O(g(n)) = O(n^2), where O can be Ω, or Ø. 