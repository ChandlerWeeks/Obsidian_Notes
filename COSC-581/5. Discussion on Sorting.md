### Is Sorting needed?
Sometimes, but it is often overused. There are times you have to sort, but it's not always necessary. They are usually comparison based, but not always (Radix sort). When performing sorting, we measure key (integers in examples) comparisons and record exchanges. 

When analyzing sorting algorithms, we need to address the following:
- Worst case
- Average case
- Stability (2 records with the same key, the order is preserved). 
- Other considerations may include
	- availability
	- simplicity
	- out-of-core applications
		- Consideration of the memory cost. The data is too big for main memory. 

# Sorting algorithms I SHOULD know
I probably don't... 

## Bubble Sort
Makes comparisons forward so that the highest value is moved to the last element. Swaps nearby values when in wrong order. 
- Makes a quadratic number of comparisons in the worst case. 
- Tough to say the average case, very dependent on the input, generally quadratic. 
- In the best case, it is linear, provided a perfect input. 
- Bubble sort is generally stable, unless you swap when keys are equal. 

## Selection Sort
Given a list of keys, if 50 are sorted, find the 51st sorted element. 
- A quadratic number of comparisons in the worst case, because it doesn't take advantage of the system. quadratic number of comparisons and record moves. 
- If its already sorted, it still makes comparisons, but does not move any keys. 
- It's average case is also difficult to exactly determine. 
- Selection sort is generally stable, but it can be implemented in an unstable way, but inserting the same values the same. Swapping the selection results in instability, but increases record moves to quadratic. 

## Insertion Sort
Insertion sort inserts items into a new array, rather than swapping them in the current array. It's like inserting tests into a stack based on last name. Straight insertion involves linearly searching our insertion array. Very intuitive. 
- Worst Case: Quadratic number of comparisons, and quadratic of record moves, to move existing records. Using a binary search insertion uses nlog(n) comparisons, but still quadratic record moves. 
- Best Case: quadratic number of comparisons for linear insertion, nlog(n) for binary insertion. Does not require record moves though. 
- Stability: linear insertion is stable when programmed correctly, while binary search can be programmed stably, but is generally more difficult. 

## Counting Sort
Counting sort is a non-comparison based sorting algorithm. We use the original version, NOT the book's version. We store the count of a record. Stores the number of records whos keys are STRICTLY smaller, to store where it goes. 

Worst case: Uses a quadratic number of comparisons, but a linear number of moves. Does NOT kill stability. 
Stability: Counting sort is stable when strictly counting cases smaller than it. 

## Merge Sort
Works downwards to divide the problem, then back up to conquer the problem, merging the divided problems. 

Worst Case: All parts of merge sort are nlog(n), but you need to be careful with the problem divided into unequal parts. Mergesort -> mergesort -> merge. 
Stability: Merge sort is stable, because you never swap values in the same position. 

## Heap Sort
Build a heap, then extract the data from it, then reheapify, and so on. 

Worst Case: Big constant of proportionality, but it is nlog(n). heapify requires log(n) computations, done n times. Its main advantage is if your data is coincidentally already in a heap. 
Stability: Depends on how you do it. If you build your heap and swap the parent and child of the same value, Heap sort is stable. 

## Quick Sort
Quicksort divides the problem. partion -> Quicksort(left) -> quicksort(right). if the leftmost is smaller than pivot, swap them, then divide. 

Worst Case: quadratic, but we can make it into nlogn. but theres consequences.