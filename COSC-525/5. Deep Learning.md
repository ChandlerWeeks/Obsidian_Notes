Make sure to understand supervised vs unsupervised learning, along with terms such as samples, dimensions, features. Understand parametric vs non-parametric learning. 
## The bridge from machine learning to deep learning
- Question: Is deep learning just deeper machine learning?
	- CNN's have two features that distinguish them. 
- Question: Is deep learning a classifier?
	- Engineered features vs. automatic features. 
- Supervised vs unsupervised
- Model-based approach vs Data-driven approach. 


Core Idea 1: Receptive field (RF) and shared weight. Given a 28x28 image, we take a part and feed it forward through the neural network. MNIST is a good proof of concept study. 

Receptive field is the subregion we focus on when using CNNs. Instead of focusing attention on the entire input, we focus on a small subregion. 

A convolution is a weighted sum. it is the receptive field, or the region, which differentiates this model from a MLP. 

Full-connected-network / Multilayer Perceptron -> each node in each layer connects to the following layer. It is a supervised approach. 
The number of parameters can be calculated using 
$\sum{(size(layer_n) * size(layer_{n+1}))}$
for a nn of 25 x 3 x 4 x 1 we have 87 parameters. 

Core idea 2: Hierarchical vision - Max Pooling

Feature map? 

Convolutional Network Framework
Input layer 28x28 -> Convolution layer 1 24x24 (6) -> pooling layer (12x12) -> 8x8 convolution layer C2 (12) -> Pooling layer 2 (4x4)  12-> fully connection layer FC 10x192 -> output layer 10x1.

CNN is not a classifier. Instead, it is a feature extractor. 